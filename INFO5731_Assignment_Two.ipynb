{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyaseri/INFO5731_FALL2020/blob/master/INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [2019 Dell labtop](https://www.amazon.com/Dell-Inspiron-5000-5570-Laptop/dp/B07N49F51N/ref=sr_1_11?crid=1IJ7UWF2F4GHH&keywords=dell%2Bxps%2B15&qid=1580173569&sprefix=dell%2Caps%2C181&sr=8-11&th=1) on amazon.\n",
        "\n",
        "(2) Collect the top 100 User Reviews of the film [Joker](https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv) from IMDB.\n",
        "\n",
        "(3) Collect the abstracts of the top 100 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(4) Collect the top 100 tweets by using hashtag [\"#CovidVaccine\"](https://twitter.com/hashtag/CovidVaccine) from Twitter. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "outputId": "e4220cc4-f6f4-4f78-99f8-1c5a2e56db1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "import requests\n",
        "from urllib.parse import urljoin\n",
        "from bs4 import BeautifulSoup as BS\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_tablelist(soup):\n",
        "    reviews = soup.find_all(\"div\", {\"class\": \"lister-item-content\"})\n",
        "\n",
        "    review_data = []\n",
        "\n",
        "    for review in reviews:\n",
        "\n",
        "        try:\n",
        "            review_content = review.find(\"div\", {\"class\": \"text show-more__control\"}).text.strip()\n",
        "        except:\n",
        "            review_content = review.find(\"div\", {\"class\": \"text show-more__control clickable\"}).text.strip()\n",
        "\n",
        "        review_data.append(review_content)\n",
        "    return review_data\n",
        "\n",
        "main_url = 'https://www.imdb.com/'\n",
        "url = 'https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv'\n",
        "res = requests.get(url)\n",
        "soup = BS(res.text, 'html.parser')\n",
        "res.encoding = 'utf-8'\n",
        "allTablelist=[]\n",
        "tablelist = get_tablelist(soup)\n",
        "for i in tablelist:\n",
        "  allTablelist.append(i)\n",
        "\n",
        "load_more = soup.select(\".load-more-data\")\n",
        "flag = True\n",
        "if len(load_more):\n",
        "    ajaxurl = load_more[0]['data-ajaxurl']\n",
        "    main_url = main_url + ajaxurl + \"?ref_=undefined&paginationKey=\"\n",
        "    try:\n",
        "        key = load_more[0]['data-key']\n",
        "    except KeyError:\n",
        "        flag = False\n",
        "else:\n",
        "    flag = False\n",
        "\n",
        "while flag:\n",
        "    url = main_url + key\n",
        "    res = requests.get(url)\n",
        "    res.encoding = 'utf-8'\n",
        "    soup = BS(res.text, 'html.parser')\n",
        "    tablelist2 = get_tablelist(soup)\n",
        "    if len(allTablelist) == 100:\n",
        "      break\n",
        "    for i in tablelist2:\n",
        "        allTablelist.append(i)\n",
        "    load_more = soup.select(\".load-more-data\")\n",
        "    if len(load_more):\n",
        "        key = load_more[0]['data-key']\n",
        "    else:\n",
        "        flag = False\n",
        "\n",
        "data = np.array(allTablelist)\n",
        "data = pd.DataFrame(data, columns=['review_content'])\n",
        "data.shape\n",
        "data.to_csv('review_data.csv')\n",
        "data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>A mentally ill person without talents (or inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>What a legendary character and what a legendar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>While I enjoyed the film, it felt pretty short...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Disturbing. Just got out of the movie. My humo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Wow I honestly gotta tell you, it's one of the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       review_content\n",
              "0   Every once in a while a movie comes, that trul...\n",
              "1   This is a movie that only those who have felt ...\n",
              "2   Truly a masterpiece, The Best Hollywood film o...\n",
              "3   Joaquin Phoenix gives a tour de force performa...\n",
              "4   Most of the time movies are anticipated like t...\n",
              "..                                                ...\n",
              "95  A mentally ill person without talents (or inte...\n",
              "96  What a legendary character and what a legendar...\n",
              "97  While I enjoyed the film, it felt pretty short...\n",
              "98  Disturbing. Just got out of the movie. My humo...\n",
              "99  Wow I honestly gotta tell you, it's one of the...\n",
              "\n",
              "[100 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "outputId": "65609431-b802-4c0e-f53f-35203960f907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Convert to lowercase\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "data['review_content'].head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie come truly make impact joaquins pe...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film one best...\n",
              "3    joaquin phoenix give tour de force performance...\n",
              "4    time movie anticipated like end falling short ...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdlW3VDVNzzm",
        "outputId": "87dcbf1e-a94e-4ca8-ce33-3abfd68a17b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Remove punctuation \n",
        "data['review_content'] = data['review_content'].str.replace('[^\\w\\s]','')\n",
        "data['review_content'].head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie come truly make impact joaquins pe...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film one best...\n",
              "3    joaquin phoenix give tour de force performance...\n",
              "4    time movie anticipated like end falling short ...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg-uSV5TN8N2",
        "outputId": "78cdf9d1-c4cc-47c4-e65f-5c911906abbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk8rG9hMOBbm",
        "outputId": "94ad912e-1f49-487d-be4d-78eac8921241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Remove stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "data['review_content'].head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie come truly make impact joaquins pe...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film one best...\n",
              "3    joaquin phoenix give tour de force performance...\n",
              "4    time movie anticipated like end falling short ...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfu0bUm-OCo_",
        "outputId": "090d73cc-5325-47e8-d310-8fd345c65800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Remove special characters\n",
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cta6enC6OFnf",
        "outputId": "7aa1447c-f555-4a82-9d90-4fa3c29fac59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Remove special characters\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x.strip(string.punctuation) for x in x.split()))  \n",
        "data['review_content']"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     every movie come truly make impact joaquins pe...\n",
              "1     movie felt alone isolated truly relate underst...\n",
              "2     truly masterpiece best hollywood film one best...\n",
              "3     joaquin phoenix give tour de force performance...\n",
              "4     time movie anticipated like end falling short ...\n",
              "                            ...                        \n",
              "95    mentally ill person without talent intelligenc...\n",
              "96    legendary character legendary performance acto...\n",
              "97    enjoyed film felt pretty short end appeared sc...\n",
              "98    disturbing got movie humor much better seeing ...\n",
              "99    wow honestly gotta tell one best movie ive see...\n",
              "Name: review_content, Length: 100, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyVnW_wROIGZ",
        "outputId": "811cd44d-c02d-4260-c56c-735bfee31f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Remove numbers\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join(x for x in x.split() if not x.isdigit()))\n",
        "data['review_content']"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     every movie come truly make impact joaquins pe...\n",
              "1     movie felt alone isolated truly relate underst...\n",
              "2     truly masterpiece best hollywood film one best...\n",
              "3     joaquin phoenix give tour de force performance...\n",
              "4     time movie anticipated like end falling short ...\n",
              "                            ...                        \n",
              "95    mentally ill person without talent intelligenc...\n",
              "96    legendary character legendary performance acto...\n",
              "97    enjoyed film felt pretty short end appeared sc...\n",
              "98    disturbing got movie humor much better seeing ...\n",
              "99    wow honestly gotta tell one best movie ive see...\n",
              "Name: review_content, Length: 100, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otwfRpTKOMoe",
        "outputId": "370c94a9-1a29-4901-a4b3-7e32f4d84561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Spell correction\n",
        "from textblob import TextBlob\n",
        "data['review_content'][:5].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie come truly make impact joaquins pe...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film one best...\n",
              "3    joaquin phoenix give tour de force performance...\n",
              "4    time movie anticipated like end falling short ...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfkpz03FOQIO",
        "outputId": "75d41f2c-e69f-4bc2-d24c-6bc06a3bb5f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "st = PorterStemmer()\n",
        "data['review_content'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    everi movi come truli make impact joaquin perf...\n",
              "1    movi felt alon isol truli relat understand mot...\n",
              "2    truli masterpiec best hollywood film one best ...\n",
              "3    joaquin phoenix give tour de forc perform fear...\n",
              "4    time movi anticip like end fall short way shor...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cOJa-YfOVYy",
        "outputId": "f790a11f-8f00-432e-cb71-5986da96d730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Lemmatization\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "data['review_content'] = data['review_content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "data['review_content'].head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    every movie come truly make impact joaquins pe...\n",
              "1    movie felt alone isolated truly relate underst...\n",
              "2    truly masterpiece best hollywood film one best...\n",
              "3    joaquin phoenix give tour de force performance...\n",
              "4    time movie anticipated like end falling short ...\n",
              "Name: review_content, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "outputId": "cf5d7654-96d5-47b2-f471-7a0e8254ab59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7RzTAWtOjV-",
        "outputId": "ba9bd3d4-e26a-4368-f9fc-788d4124723e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "from nltk import word_tokenize, pos_tag, pos_tag_sents\n",
        "data['POSTags'] =  pos_tag_sents( data['review_content'].apply(word_tokenize).tolist() )\n",
        "print(data)\n",
        "\n",
        "pos = data['POSTags'].to_list()\n",
        "pos\n",
        "nouns = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('N')):\n",
        "       nouns+=1\n",
        "res = \"nouns:{}\".format(nouns)\n",
        "print(res)\n",
        "verb = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('V')):\n",
        "       verb+=1\n",
        "res_1 = \"verb:{}\".format(verb)\n",
        "print(res_1)\n",
        "adverb = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('R')):\n",
        "       adverb+=1\n",
        "res_2 = \"adverb:{}\".format(adverb)\n",
        "print(res_2)\n",
        "adj = 0\n",
        "for x in pos:\n",
        "  for a,b in x:\n",
        "    if(b.startswith('J')):\n",
        "       adj+=1\n",
        "res_3 = \"adj:{}\".format(adj)\n",
        "print(res_3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                       review_content                                            POSTags\n",
            "0   every movie come truly make impact joaquins pe...  [(every, DT), (movie, NN), (come, VBN), (truly...\n",
            "1   movie felt alone isolated truly relate underst...  [(movie, NN), (felt, VBD), (alone, RB), (isola...\n",
            "2   truly masterpiece best hollywood film one best...  [(truly, RB), (masterpiece, JJ), (best, JJS), ...\n",
            "3   joaquin phoenix give tour de force performance...  [(joaquin, NN), (phoenix, NN), (give, VB), (to...\n",
            "4   time movie anticipated like end falling short ...  [(time, NN), (movie, NN), (anticipated, VBN), ...\n",
            "..                                                ...                                                ...\n",
            "95  mentally ill person without talent intelligenc...  [(mentally, RB), (ill, JJ), (person, NN), (wit...\n",
            "96  legendary character legendary performance acto...  [(legendary, JJ), (character, NN), (legendary,...\n",
            "97  enjoyed film felt pretty short end appeared sc...  [(enjoyed, VBN), (film, NN), (felt, VBD), (pre...\n",
            "98  disturbing got movie humor much better seeing ...  [(disturbing, VBG), (got, VBD), (movie, NN), (...\n",
            "99  wow honestly gotta tell one best movie ive see...  [(wow, NN), (honestly, RB), (got, VBD), (ta, R...\n",
            "\n",
            "[100 rows x 2 columns]\n",
            "nouns:3544\n",
            "verb:1537\n",
            "adverb:718\n",
            "adj:1668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaF0Fsd6PKHe",
        "outputId": "82134abe-ab30-4c47-97b2-890778a53dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "#entity recognition\n",
        "!pip install spacy"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWUv6KIzPN-L",
        "outputId": "62130c14-1cb3-4928-af23-6045e356d66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "data['review_content']\n",
        "list = data['review_content'].tolist()\n",
        "list[0]\n",
        "for x in list:\n",
        "   doc = (nlp(x))\n",
        "   print([(X.text, X.label_) for X in doc.ents])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[('one', 'CARDINAL')]\n",
            "[('hollywood', 'GPE'), ('one', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('de force', 'ORG'), ('portrayal', 'NORP')]\n",
            "[('dark joker', 'ORG'), ('villain', 'GPE')]\n",
            "[('joaquin phoneix', 'PERSON')]\n",
            "[('arthur madness', 'PERSON'), ('phillips', 'PERSON')]\n",
            "[('yesterday', 'DATE'), ('venice', 'GPE'), ('itjoker', 'PERSON'), ('venice', 'GPE'), ('nolans', 'NORP'), ('scorsese', 'NORP'), ('hollywood', 'GPE')]\n",
            "[('joaquin', 'PERSON'), ('niro joaquin', 'PERSON')]\n",
            "[('one', 'CARDINAL'), ('year', 'DATE')]\n",
            "[('joker venice', 'PERSON'), ('joaquin', 'PERSON'), ('robert', 'PERSON')]\n",
            "[('phoenix superb', 'ORG'), ('arthur mental state deep psychological', 'ORG'), ('one', 'CARDINAL'), ('three', 'CARDINAL')]\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "[('joaquin phoenix', 'PERSON'), ('todd phillips', 'PERSON'), ('disturbed', 'ORG')]\n",
            "[('joaquin phoenix', 'PERSON')]\n",
            "[('year ago', 'DATE'), ('joaquin phoenix', 'PERSON'), ('jack nicholson', 'PERSON')]\n",
            "[]\n",
            "[('joaquin phoenix joker', 'PERSON'), ('joker jack nicholsons', 'PERSON'), ('phoenix', 'GPE'), ('one', 'CARDINAL')]\n",
            "[('phoenix outstandingso', 'ORG'), ('kinda justeh', 'PERSON')]\n",
            "[('ten', 'CARDINAL'), ('drama thriller', 'PERSON')]\n",
            "[('year', 'DATE'), ('10', 'CARDINAL'), ('phoenix', 'GPE'), ('emptyfilm year', 'EVENT')]\n",
            "[('one', 'CARDINAL'), ('groupi', 'PERSON'), ('first', 'ORDINAL'), ('last decade', 'DATE'), ('joaquin phoenix', 'PERSON'), ('thingjoker', 'PERSON')]\n",
            "[('joaquin phoenix', 'PERSON'), ('oscar joaquin', 'PERSON'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('todd philip', 'PERSON'), ('one', 'CARDINAL'), ('joaquin phoenix joker', 'PERSON'), ('jack heath', 'PERSON')]\n",
            "[('hour', 'TIME'), ('standup', 'PERSON'), ('mehe', 'ORG'), ('homocideit', 'GPE')]\n",
            "[('phoenix show u joker', 'ORG'), ('u power', 'ORG'), ('philip hand perfect choice music camera angle lighting', 'ORG'), ('today', 'DATE'), ('first', 'ORDINAL')]\n",
            "[('phoenix', 'GPE'), ('phoenix movieas', 'PERSON'), ('recent year', 'DATE'), ('one', 'CARDINAL'), ('wayne', 'PERSON')]\n",
            "[('half', 'CARDINAL'), ('lifethere', 'GPE')]\n",
            "[('arthur fleck', 'PERSON'), ('thomas wayne', 'PERSON'), ('s', 'ORG')]\n",
            "[('movieif joker one', 'ORG'), ('nolans', 'NORP'), ('druggedup psycho', 'PERSON'), ('phoenix joker', 'ORG'), ('phoenix joker', 'ORG'), ('two hour', 'TIME'), ('universe doubt', 'PERSON'), ('moviethere', 'PERSON')]\n",
            "[('joaquin phoenix', 'PERSON'), ('todd phillips', 'PERSON'), ('superb', 'PERSON')]\n",
            "[('phoenix', 'GPE'), ('couple hour', 'TIME'), ('second', 'ORDINAL'), ('one', 'CARDINAL')]\n",
            "[('zero', 'CARDINAL'), ('zero', 'CARDINAL')]\n",
            "[('champion movie joker life', 'ORG')]\n",
            "[('joaquins', 'PERSON')]\n",
            "[('night', 'TIME'), ('august', 'DATE'), ('venice international film festival', 'ORG'), ('joaquin phoenix', 'ORG'), ('arthur', 'PERSON'), ('phoenix', 'PERSON'), ('joaquin phoenix', 'PERSON'), ('1970s', 'DATE'), ('gotham city', 'GPE'), ('two', 'CARDINAL'), ('martin', 'ORG'), ('scorsese', 'NORP'), ('standup comedy king comedy', 'PERSON'), ('standup comedian', 'PERSON'), ('house', 'ORG'), ('arthur', 'PERSON'), ('second', 'ORDINAL'), ('wayne', 'PERSON'), ('half', 'CARDINAL'), ('murray franklin', 'PERSON'), ('phoenix', 'GPE'), ('robert de niros', 'PERSON')]\n",
            "[]\n",
            "[('two', 'CARDINAL'), ('1best', 'CARDINAL'), ('3original', 'CARDINAL'), ('hollywood', 'GPE')]\n",
            "[('arthur fleck life invalid', 'ORG'), ('weekly', 'DATE'), ('robert de niro', 'PERSON'), ('fantasy', 'GPE'), ('first', 'ORDINAL')]\n",
            "[]\n",
            "[('one', 'CARDINAL')]\n",
            "[('joaquin portrayal', 'PERSON'), ('joaquin phoenix', 'PERSON'), ('cgi super power great villain', 'ORG')]\n",
            "[('one', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[('joaquin phoenix amazing performance', 'PERSON'), ('foundation joker', 'ORG'), ('two', 'CARDINAL')]\n",
            "[('hour', 'TIME'), ('hour', 'TIME'), ('1010the', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('one', 'CARDINAL')]\n",
            "[('first', 'ORDINAL')]\n",
            "[('joaquÃ­n phoenix', 'ORG')]\n",
            "[('arthur', 'ORG'), ('first', 'ORDINAL'), ('arthur', 'PERSON'), ('one', 'CARDINAL'), ('last decade', 'DATE'), ('joaquin', 'PERSON'), ('joaquin choreography', 'ORG'), ('one', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[('arthur masterful de niro', 'PERSON'), ('nod jerry lewis', 'PERSON')]\n",
            "[('el critique', 'GPE'), ('alfred hitchcock', 'PERSON'), ('shell', 'ORG'), ('stellar', 'NORP'), ('joaquin', 'PERSON'), ('bruce wayne', 'PERSON'), ('murray franklincharacter development', 'PERSON'), ('seven', 'CARDINAL'), ('70', 'CARDINAL'), ('todd philip', 'PERSON'), ('thomas wayne', 'PERSON'), ('truman', 'PERSON'), ('american', 'NORP'), ('wtf', 'ORG'), ('five', 'CARDINAL'), ('one', 'CARDINAL'), ('thousand', 'CARDINAL'), ('shakespeare', 'PERSON')]\n",
            "[('hollywood', 'GPE'), ('riffraff suffering', 'PERSON'), ('hollywood', 'GPE'), ('hundred million', 'CARDINAL'), ('one', 'CARDINAL'), ('zero', 'CARDINAL'), ('arthur', 'PERSON'), ('two', 'CARDINAL'), ('joker', 'GPE'), ('many year', 'DATE'), ('boon hollywood', 'PERSON'), ('second', 'ORDINAL'), ('one', 'CARDINAL')]\n",
            "[('hour', 'TIME'), ('guy oscar', 'PERSON')]\n",
            "[]\n",
            "[('hour', 'TIME')]\n",
            "[]\n",
            "[('kinda boringit', 'PERSON')]\n",
            "[]\n",
            "[('one', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[('couple week', 'DATE'), ('joaquin phoenix', 'PERSON')]\n",
            "[]\n",
            "[]\n",
            "[('joaquin creativity', 'PERSON')]\n",
            "[('absolute disappointment', 'ORG'), ('hype', 'GPE'), ('phoenix', 'GPE')]\n",
            "[]\n",
            "[('one', 'CARDINAL'), ('maybephoenixs joker', 'ORG'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('three', 'CARDINAL'), ('jack napier', 'PERSON'), ('first keaton', 'ORG'), ('phoenix', 'GPE'), ('first', 'ORDINAL'), ('one', 'CARDINAL'), ('second', 'ORDINAL'), ('tony rich', 'PERSON'), ('jerkand bruce wayne', 'PERSON'), ('batman joker', 'ORG'), ('year', 'DATE'), ('one', 'CARDINAL'), ('second', 'ORDINAL'), ('one', 'CARDINAL')]\n",
            "[('hollywood', 'GPE'), ('hollywood rich', 'ORG')]\n",
            "[('one', 'CARDINAL'), ('phoenix', 'GPE')]\n",
            "[('scorsese', 'NORP'), ('one', 'CARDINAL'), ('dozen', 'CARDINAL'), ('arthur', 'PERSON'), ('portrayal joker', 'ORG'), ('arthur', 'PERSON'), ('thomas wayne character', 'PERSON'), ('first', 'ORDINAL'), ('two', 'CARDINAL'), ('two', 'CARDINAL'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('decade later', 'DATE'), ('scorsese', 'NORP'), ('tim burton', 'PERSON'), ('today', 'DATE')]\n",
            "[('two', 'CARDINAL'), ('one', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('god', 'PERSON'), ('war day', 'DATE'), ('arthur', 'PERSON'), ('arthur', 'PERSON'), ('arthur', 'PERSON'), ('gruesome joker', 'ORG'), ('arthur jokermixed', 'PERSON'), ('70', 'CARDINAL'), ('scorsese', 'NORP'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('three', 'CARDINAL')]\n",
            "[]\n",
            "[('han', 'NORP'), ('zimmer', 'ORG')]\n",
            "[]\n",
            "[('joaquin phoenix', 'PERSON'), ('arthur fleck', 'PERSON'), ('quotidian', 'NORP'), ('robert de niro', 'PERSON'), ('murray franklin', 'PERSON'), ('endoftheyear', 'ORG')]\n",
            "[('year', 'DATE')]\n",
            "[]\n",
            "[]\n",
            "[('joaquin phoenix', 'PERSON')]\n",
            "[('evolves joker end joker', 'ORG'), ('joaquin', 'PERSON')]\n",
            "[('turkey', 'GPE'), ('le watch', 'ORG'), ('supervillians', 'NORP'), ('hung long', 'PERSON'), ('wheelsif', 'PERSON'), ('jack nicholson', 'PERSON')]\n",
            "[('first', 'ORDINAL')]\n",
            "[('one', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('joaquin phoenix', 'PERSON'), ('one', 'CARDINAL')]\n",
            "[('performance joaquin', 'PERSON'), ('mentaly ill', 'PERSON'), ('title arthur clown', 'ORG'), ('universe feld', 'PERSON')]\n",
            "[('joaquin phoenix', 'PERSON'), ('todd phillips', 'PERSON'), ('resistance incel', 'PERSON'), ('robert de niro', 'PERSON')]\n",
            "[]\n",
            "[]\n",
            "[('joker masterpiece', 'ORG'), ('flawless board', 'ORG'), ('hollywood', 'GPE')]\n",
            "[('new joker rivalry', 'ORG')]\n",
            "[('yesterday day', 'DATE'), ('mcdonalds', 'ORG')]\n",
            "[('half', 'CARDINAL'), ('last minute', 'TIME'), ('gore', 'PERSON')]\n",
            "[('one', 'CARDINAL')]\n",
            "[('joaquin phoenix', 'PERSON'), ('christian', 'NORP'), ('robert de niro', 'PERSON')]\n",
            "[]\n",
            "[]\n",
            "[('s itjoaquin', 'PRODUCT'), ('phoenix', 'GPE')]\n",
            "[('first', 'ORDINAL')]\n",
            "[('one', 'CARDINAL'), ('year', 'DATE'), ('joaquin phoenix', 'PERSON'), ('mouth', 'PERSON'), ('half', 'CARDINAL'), ('first', 'ORDINAL'), ('one', 'CARDINAL')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M68EPzNMJzI",
        "outputId": "61f7d70f-b84a-4cf1-bf63-e377767711d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "'''\n",
        "Write your explanations of the constituency parsing tree and dependency parsing tree here\n",
        "\n",
        "These processes are helpful in word processing systems and grammar correction.\n",
        "Constituency parsing: \n",
        "-Constituency parsing displays syntactic structure of a sentence of a written language where the words are organized according to their type of grammer.\n",
        "-In a sentence, it breaks down the sentence into sub phrases.\n",
        " \n",
        "Dependency parsing: \n",
        "-It displays grammatical structure where each word represents a node and followed by links to its dependents.\n",
        "-Dependency parsing displays the relation between words.\n",
        "\n",
        "'''"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nWrite your explanations of the constituency parsing tree and dependency parsing tree here\\n\\nThese processes are helpful in word processing systems and grammar correction.\\nConstituency parsing: \\n-Constituency parsing displays syntactic structure of a sentence of a written language where the words are organized according to their type of grammer.\\n-In a sentence, it breaks down the sentence into sub phrases.\\n \\nDependency parsing: \\n-It displays grammatical structure where each word represents a node and followed by links to its dependents.\\n-Dependency parsing displays the relation between words.\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}